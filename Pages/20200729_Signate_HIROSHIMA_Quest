◆2020/7/29 SIGNATE ひろしまquest【球種予測】と【コース予測】　結果：27/481(銀メダル)、69/284(銅メダル)

◎試したこと
　・欠損値処理(Simple Inpute、fillna、dropna)　
  ・ラベルエンコーディング、one-hot-encoding
　・特徴量選択(RFE、RFECV)　
  ・次元削減(主成分分析、tsne)　
　・特徴量追加(外部データ、ラグ変数、統計量データ、自分で生成したもの)
　・アルゴル選択(LightGBM、MLPClassifier、Random Forest、Logistic regression)　
  ・pseudo_labeling　
  ・Advertisal_validation
　・stacking　・サブミットファイルのアンサンブル

◎所感
　・nanが多い列に関しては、dropもしくはfillnaしてよい。
　・決定木系のアルゴリズムではlabel-encordingがいい気がする(category_encoderを使用)。
　・特徴量同士の相関係数を可視化し、相関の強いものを削除したら精度が上がった(多重共線性)
　・自作の特徴量が非常に効いた(ex 身長と体重からBMI算出 など)
　・決定木ベースのアルゴリズム以外には標準化処理が必要である。
　・モデルの評価をする上で学習曲線が非常に役立った。
　・近年のコンペで使用率の高いpseudo_labeling、stacking、Advertisal_validationなど新しい知見が得られた。
　・不均衡データであったため、over_sampling(SMOTE)してみたが、精度が下がった。
　・学習が止まった際に、callback関数でパラメータ(学習率など)を変化させると再び学習が進むようになった。
　・pseudo_labelingやAdvertisal_validationは単体モデルでは精度が低かったが、アンサンブルすると精度が上がった。
　・アンサンブルするモデルは、学習レコード数、特徴量数、ハイパラ、cv方法など違うほど良い。
　・相関の低いアルゴリズムのモデル同士をアンサンブルすると非常に精度がよくなる(決定木の深さや線形モデルの正則化項など)
　・LightGBMシングルモデルよりも複数アルゴリズムのモデルをアンサンブルした方が精度がよくなった(処理によるのか？)

◎反省点
　・EDAが少々足りなかったか(もっとデータをしっかりと見るべきだった(周期性や頻度を知る))　
　・線形アルゴリズムに対してlabel-encordingを使用していたため、one-hot-encodingを使うべきだった。
　・交差検証時に、層化抽出かGroupkfordかTimeSeriesSplitか決めきれなかった(それぞれどういうときに使用するのか勉強する)
　・目的変数のラグ特徴量の取り方をもう少し勉強する。
　・早い段階で脳死でOptunaによるハイパラチューニングをしてしまった(もっと終盤でよい)
　・作ったモデルはすべてDumpしておいたほうが良いかも
　・もっと様々なアルゴリズムでモデルを作ってみてから、ハイパラチューニングとアンサンブルするべき
　・後半は脳死のサブミットファイルアンサンブルが多かった(今回は単純平均でよかったが。。)
　・終始PBのスコアを気にしてしまっていた(Trust your CV)
　・サブミットファイルのログを残すべきだった(どれをアンサンブルしたらいいかわからなくなった)
　・全体的に「何となく」で次の試行をしまっていた(仮説を立て予測し、結果から都度考察する習慣をつける)。
